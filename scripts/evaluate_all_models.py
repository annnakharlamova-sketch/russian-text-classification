import sys
sys.path.append('src')

from utils import save_experiment_results
from evaluation import Evaluator
import yaml
import pandas as pd
import os
from sklearn.model_selection import train_test_split
import pickle
import numpy as np
import time
from datetime import datetime

print("–û–¶–ï–ù–ö–ê –ò –°–†–ê–í–ù–ï–ù–ò–ï –í–°–ï–• –ú–û–î–ï–õ–ï–ô")

# –ó–∞–≥—Ä—É–∂–∞–µ–º –∫–æ–Ω—Ñ–∏–≥
config = yaml.safe_load(open('configs/experiments/main.yaml', 'r', encoding='utf-8'))

# –°–æ–∑–¥–∞–µ–º –ø–∞–ø–∫—É –¥–ª—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
results_dir = "results"
os.makedirs(results_dir, exist_ok=True)

# –°–æ–∑–¥–∞–µ–º –æ—Ü–µ–Ω—â–∏–∫
evaluator = Evaluator(config)

results = []

def evaluate_and_save_model(model, vectorizer, X_test, y_test, dataset_name, model_name, preprocess_name, train_time=0, fold=None):
    """
    –û—Ü–µ–Ω–∫–∞ –º–æ–¥–µ–ª–∏ –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–º —Ñ–æ—Ä–º–∞—Ç–µ
    """
    from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score
    
    # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º —Ç–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ
    X_test_vec = vectorizer.transform(X_test)
    
    # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
    start_time = time.time()
    y_pred = model.predict(X_test_vec)
    predict_time = time.time() - start_time
    
    # –í—ã—á–∏—Å–ª—è–µ–º –º–µ—Ç—Ä–∏–∫–∏ (MACRO averaging –∫–∞–∫ –≤ —Å—Ç–∞—Ç—å–µ)
    accuracy = accuracy_score(y_test, y_pred)
    precision = precision_score(y_test, y_pred, average='macro', zero_division=0)
    recall = recall_score(y_test, y_pred, average='macro', zero_division=0)
    macro_f1 = f1_score(y_test, y_pred, average='macro', zero_division=0)
    
    # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –≤ —Ç—Ä–µ–±—É–µ–º–æ–º —Ñ–æ—Ä–º–∞—Ç–µ
    results_dict = {
        'dataset': dataset_name,
        'model': model_name,
        'preprocess': preprocess_name,
        'fold': fold,  # None –¥–ª—è —Ç–µ—Å—Ç–∞, –Ω–æ–º–µ—Ä –¥–ª—è CV
        'seed': 42,
        'accuracy': round(accuracy, 4),
        'macro_f1': round(macro_f1, 4),
        'precision': round(precision, 4),
        'recall': round(recall, 4),
        'train_time_sec': round(train_time, 2)
    }
    
    # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π CSV
    save_experiment_results(results_dict)
    
    return results_dict

# –û—Ü–µ–Ω–∏–≤–∞–µ–º –Ω–∞ –≤—Å–µ—Ö –∫–æ—Ä–ø—É—Å–∞—Ö –∏ –ø–∞–π–ø–ª–∞–π–Ω–∞—Ö
for corpus_name in ['rureviews', 'rusentiment', 'taiga']:
    print(f"\n{'='*50}")
    print(f"–û–¶–ï–ù–ö–ê –ù–ê –ö–û–†–ü–£–°–ï: {corpus_name}")
    print(f"{'='*50}")
    
    for pipeline in ['P0', 'P1', 'P2', 'P3']:
        print(f"\n –ü–∞–π–ø–ª–∞–π–Ω: {pipeline} ")
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
        data_path = f"processed_data/{corpus_name}/{pipeline}.csv"
        if not os.path.exists(data_path):
            print(f" –§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {data_path}")
            continue
            
        df = pd.read_csv(data_path)
        print(f"–ó–∞–≥—Ä—É–∂–µ–Ω–æ: {len(df):,} –ø—Ä–∏–º–µ—Ä–æ–≤")
        
        # –î–ª—è –±–æ–ª—å—à–∏—Ö –∫–æ—Ä–ø—É—Å–æ–≤ –±–µ—Ä–µ–º –ø–æ–¥–≤—ã–±–æ—Ä–∫—É –¥–ª—è –±—ã—Å—Ç—Ä–æ–π –æ—Ü–µ–Ω–∫–∏
        if len(df) > 10000:
            df = df.sample(10000, random_state=42)
            print(f"–ë–µ—Ä–µ–º –ø–æ–¥–≤—ã–±–æ—Ä–∫—É 10K –¥–ª—è –æ—Ü–µ–Ω–∫–∏")
        
        # –†–∞–∑–¥–µ–ª—è–µ–º –¥–∞–Ω–Ω—ã–µ
        X_train, X_test, y_train, y_test = train_test_split(
            df['text'].tolist(), 
            df['label'].tolist(), 
            test_size=0.2, 
            random_state=42,
            stratify=df['label']
        )
        
        print(f"–û—Ü–µ–Ω–∫–∞ –Ω–∞: Train {len(X_train):,}, Test {len(X_test):,}")
        
        # –û—Ü–µ–Ω–∏–≤–∞–µ–º –∫–ª–∞—Å—Å–∏—á–µ—Å–∫–∏–µ –º–æ–¥–µ–ª–∏
        for model_type in ['bow_logreg', 'tfidf_svm']:
            model_path = f"trained_models/final/{corpus_name}_{pipeline}_{model_type}_classifier.pkl"
            vectorizer_path = f"trained_models/final/{corpus_name}_{pipeline}_{model_type}_vectorizer.pkl"
            
            if os.path.exists(model_path) and os.path.exists(vectorizer_path):
                try:
                    print(f" –û—Ü–µ–Ω–∫–∞ {model_type}...")
                    
                    # –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å –∏ –≤–µ–∫—Ç–æ—Ä–∏–∑–∞—Ç–æ—Ä
                    with open(model_path, 'rb') as f:
                        model = pickle.load(f)
                    with open(vectorizer_path, 'rb') as f:
                        vectorizer = pickle.load(f)
                    
                    # –û—Ü–µ–Ω–∏–≤–∞–µ–º –∏ —Å–æ—Ö—Ä–∞–Ω—è–µ–º –≤ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–º —Ñ–æ—Ä–º–∞—Ç–µ
                    model_results = evaluate_and_save_model(
                        model=model,
                        vectorizer=vectorizer,
                        X_test=X_test,
                        y_test=y_test,
                        dataset_name=corpus_name,
                        model_name=model_type,
                        preprocess_name=pipeline,
                        train_time=0,  # –í—Ä–µ–º—è –æ–±—É—á–µ–Ω–∏—è –º–æ–∂–Ω–æ –¥–æ–±–∞–≤–∏—Ç—å –∏–∑ –ª–æ–≥–æ–≤
                        fold=None  # –î–ª—è —Ç–µ—Å—Ç–æ–≤–æ–≥–æ –Ω–∞–±–æ—Ä–∞
                    )
                    
                    print(f"    {model_type}: Accuracy={model_results['accuracy']:.4f}, F1-macro={model_results['macro_f1']:.4f}")
                    
                    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –¥–ª—è —Å–≤–æ–¥–∫–∏
                    results.append({
                        'corpus': corpus_name,
                        'pipeline': pipeline,
                        'model': model_type,
                        'accuracy': model_results['accuracy'],
                        'precision': model_results['precision'],
                        'recall': model_results['recall'],
                        'f1': model_results['macro_f1'],
                        'train_size': len(X_train),
                        'test_size': len(X_test),
                        'status': 'success'
                    })
                    
                except Exception as e:
                    print(f"    –û—à–∏–±–∫–∞ –æ—Ü–µ–Ω–∫–∏ {model_type}: {e}")
                    results.append({
                        'corpus': corpus_name,
                        'pipeline': pipeline,
                        'model': model_type,
                        'status': 'error',
                        'error': str(e)
                    })
            else:
                print(f"     –ú–æ–¥–µ–ª—å {model_type} –Ω–µ –Ω–∞–π–¥–µ–Ω–∞")
        
        # –î–ª—è LSTM - –∞–Ω–∞–ª–æ–≥–∏—á–Ω–∞—è –æ—Ü–µ–Ω–∫–∞ –∫–æ–≥–¥–∞ –º–æ–¥–µ–ª—å –±—É–¥–µ—Ç –≥–æ—Ç–æ–≤–∞
        lstm_path = f"trained_models/lstm/{corpus_name}_{pipeline}_lstm.pth"
        if os.path.exists(lstm_path):
            try:
                print(f" –û—Ü–µ–Ω–∫–∞ LSTM...")
                # –ó–¥–µ—Å—å –∫–æ–¥ –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ –∏ –æ—Ü–µ–Ω–∫–∏ LSTM –º–æ–¥–µ–ª–∏
                # lstm_results = evaluate_lstm_model(...)
                # save_experiment_results(lstm_results)
                print(f"    LSTM: –æ—Ü–µ–Ω–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞")
            except Exception as e:
                print(f"    –û—à–∏–±–∫–∞ –æ—Ü–µ–Ω–∫–∏ LSTM: {e}")

print(f"\n{'='*60}")
print(" –û–¶–ï–ù–ö–ê –í–°–ï–• –ú–û–î–ï–õ–ï–ô –ó–ê–í–ï–†–®–ï–ù–ê!")
print(f"{'='*60}")

# –°–æ—Ö—Ä–∞–Ω—è–µ–º –¥–µ—Ç–∞–ª—å–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤ —Å—Ç–∞—Ä–æ–º —Ñ–æ—Ä–º–∞—Ç–µ –¥–ª—è –æ–±—Ä–∞—Ç–Ω–æ–π —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏
results_df = pd.DataFrame(results)
results_path = f"{results_dir}/all_models_evaluation_detailed.csv"
results_df.to_csv(results_path, index=False)
print(f" –î–µ—Ç–∞–ª—å–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤: {results_path}")

# –ó–∞–≥—Ä—É–∂–∞–µ–º –∏ –ø–æ–∫–∞–∑—ã–≤–∞–µ–º —Å—Ç–∞–Ω–¥–∞—Ä—Ç–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
print(f"\n –°–¢–ê–ù–î–ê–†–¢–ò–ó–ò–†–û–í–ê–ù–ù–´–ï –†–ï–ó–£–õ–¨–¢–ê–¢–´:")
standard_results = []
for file in os.listdir(results_dir):
    if file.endswith('.csv') and not file.startswith('all_models_evaluation'):
        filepath = os.path.join(results_dir, file)
        try:
            df = pd.read_csv(filepath)
            standard_results.append(df)
            print(f"   üìä {file}: {len(df)} —Å—Ç—Ä–æ–∫")
        except:
            pass

if standard_results:
    combined_df = pd.concat(standard_results, ignore_index=True)
    combined_path = f"{results_dir}/all_standard_results.csv"
    combined_df.to_csv(combined_path, index=False)
    print(f"   –í—Å–µ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –æ–±—ä–µ–¥–∏–Ω–µ–Ω—ã –≤: {combined_path}")
    
    # –°–≤–æ–¥–∫–∞ –ø–æ –º–æ–¥–µ–ª—è–º
    print(f"\n –°–í–û–î–ö–ê –ü–û –ú–û–î–ï–õ–Ø–ú:")
    for model in combined_df['model'].unique():
        model_data = combined_df[combined_df['model'] == model]
        avg_accuracy = model_data['accuracy'].mean()
        avg_f1 = model_data['macro_f1'].mean()
        print(f"   {model}: Accuracy={avg_accuracy:.4f}, F1-macro={avg_f1:.4f}")

print(f"\n –ê–ù–ê–õ–ò–ó:")
print("   - –í—Å–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–º —Ñ–æ—Ä–º–∞—Ç–µ CSV")
print("   - –°—Ç–æ–ª–±—Ü—ã: dataset, model, preprocess, fold, seed, accuracy, macro_f1, precision, recall, train_time_sec")
print("   - –ì–æ—Ç–æ–≤–æ –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Ç–∞–±–ª–∏—Ü 1-3 '–≤ –æ–¥–∏–Ω –∫–ª–∏–∫'")