name: Russian Text Classification CI

on:
  push:
    branches: [ main, master ]
  pull_request:
    branches: [ main, master ]
  workflow_dispatch:  # Разрешает ручной запуск

env:
  PYTHON_VERSION: '3.10'

jobs:
  minimal-pipeline-test:
    name: Minimal Pipeline Test
    runs-on: ubuntu-latest
    timeout-minutes: 10  # Ограничиваем время выполнения
    
    steps:
    - name:  Checkout repository
      uses: actions/checkout@v4
      
    - name:  Set up Python ${{ env.PYTHON_VERSION }}
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}
        cache: 'pip'
    
    - name:  Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        # Минимальные зависимости для тестов
        pip install pytest scikit-learn matplotlib pandas numpy pyyaml
    
    - name:  Create test directory structure
      run: |
        mkdir -p data/rureviews
        mkdir -p data/rusentiment
        mkdir -p data/taiga
        mkdir -p results/figures
        mkdir -p results/tables
        mkdir -p trained_models
        echo " Test directories created"
        
    - name:  Create minimal toy datasets
      run: |
        python -c "
        import pandas as pd
        import os
        
        # Минимальный RuReviews dataset (5 примеров)
        reviews_data = {
            'text': [
                'Отличный товар очень доволен',
                'Плохое качество не рекомендую', 
                'Нормальный продукт за деньги',
                'Хороший сервис быстро доставили',
                'Ужасное обслуживание'
            ],
            'label': [1, 0, 1, 1, 0]
        }
        pd.DataFrame(reviews_data).to_csv('data/rureviews/reviews.csv', index=False)
        print(' RuReviews toy data created')
        
        # Минимальный RuSentiment dataset (5 примеров)  
        sentiment_data = {
            'text': [
                'Это прекрасно очень рад',
                'Ненавижу ужасное качество',
                'Нормально ничего особенного',
                'Восхитительно очень доволен',
                'Ужасно не покупайте'
            ],
            'sentiment': [2, 0, 1, 2, 0]
        }
        pd.DataFrame(sentiment_data).to_csv('data/rusentiment/train.csv', index=False)
        print(' RuSentiment toy data created')
        
        # Минимальный Taiga dataset (5 примеров)
        taiga_data = {
            'text': [
                'Интересный пост в социальной сети',
                'Обычное сообщение пользователя',
                'Важное обновление новостей',
                'Комментарий в обсуждении',
                'Запись в блоге'
            ],
            'label': [1, 0, 2, 1, 0]
        }
        pd.DataFrame(taiga_data).to_csv('data/taiga/social_dataset.csv', index=False)
        print(' Taiga toy data created')
        "
        
    - name:  Run minimal pipeline test
      run: |
        python scripts/run_minimal_pipeline.py
        
    - name:  Verify output artifacts
      run: |
        echo \" Checking generated artifacts...\"
        
        # Проверяем CSV файлы
        if [ -f \"results/tables/minimal_results.csv\" ]; then
            echo \" CSV results created\"
            echo \"CSV content:\"
            head -n 5 \"results/tables/minimal_results.csv\"
        else
            echo \" CSV results missing\"
            exit 1
        fi
        
        # Проверяем графики
        if ls results/figures/minimal_*.png 1> /dev/null 2>&1; then
            echo \" Figures created\"
            ls -la results/figures/minimal_*.png
        else
            echo \" Figures missing\" 
            exit 1
        fi
        
        echo \" All artifacts verified successfully!\"
        
    - name:  Upload artifacts
      uses: actions/upload-artifact@v4
      if: always()
      with:
        name: ci-artifacts
        path: |
          results/
        retention-days: 7